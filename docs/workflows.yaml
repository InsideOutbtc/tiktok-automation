# TikTok AI Automation Workflows
# Constitutional AI: Maximum Velocity Mode with Zero Confirmations

version: "1.0"
name: tiktok-automation-workflows

# Global settings for all workflows
settings:
  max_velocity_mode: true
  confirmation_required: false
  error_handling:
    tier1_retry_count: 3
    tier1_retry_delay: 1s
    tier2_fallback_enabled: true
    tier3_auto_restart: true
    tier4_alert_only: true
  performance:
    api_timeout: 20ms
    db_timeout: 4ms
    default_parallelism: 10

# Workflow definitions
workflows:
  
  # Main content discovery workflow
  content_discovery:
    name: "Continuous Content Discovery"
    trigger:
      type: "schedule"
      interval: "*/5 * * * *"  # Every 5 minutes
    
    steps:
      - name: "fetch_tiktok_trending"
        action: "content_sourcer.fetch_trending"
        params:
          platforms: ["tiktok"]
          limit: 50
          categories: ["fitness", "workout", "health"]
        error_handling:
          tier: 1
          fallback: "fetch_from_cache"
        
      - name: "fetch_youtube_fitness"
        action: "content_sourcer.fetch_youtube"
        params:
          query: "fitness transformation viral"
          max_results: 30
          order_by: "view_count"
        parallel: true
        
      - name: "viral_scoring"
        action: "ai_agents.viral_scout.analyze"
        input: "${fetch_tiktok_trending.output + fetch_youtube_fitness.output}"
        params:
          min_score: 0.7
          use_patterns: true
        
      - name: "store_discoveries"
        action: "database.batch_insert"
        input: "${viral_scoring.output}"
        params:
          table: "content_sources"
          on_conflict: "update"
          
      - name: "trigger_processing"
        action: "workflow.trigger"
        condition: "${viral_scoring.output.length > 0}"
        params:
          workflow: "video_processing"
          data: "${viral_scoring.output}"

  # Video processing pipeline
  video_processing:
    name: "Intelligent Video Processing"
    trigger:
      type: "event"
      event: "new_content_discovered"
    
    max_parallel: 5
    
    steps:
      - name: "download_video"
        action: "video_processor.download"
        params:
          quality: "highest"
          format: "mp4"
        error_handling:
          tier: 2
          fallback_action: "video_processor.download_alternative"
          
      - name: "analyze_content"
        action: "smart_clipper.analyze"
        input: "${download_video.output}"
        params:
          detect_scenes: true
          identify_hooks: true
          track_energy: true
          
      - name: "generate_clips"
        action: "smart_clipper.create_clips"
        input: "${analyze_content.output}"
        params:
          min_duration: 15
          max_duration: 60
          overlap: 5
        parallel: true
        
      - name: "ai_clip_selection"
        action: "ai_agents.clip_selector.rank"
        input: "${generate_clips.output}"
        params:
          top_k: 5
          criteria: ["hook_strength", "viral_potential", "retention"]
          
      - name: "apply_effects"
        action: "video_editor.apply_effects"
        input: "${ai_clip_selection.output}"
        params:
          effects: ["auto_caption", "energy_boost", "hook_enhance"]
          quality: "high"
        parallel: true
        
      - name: "generate_metadata"
        action: "ai_agents.hook_writer.generate"
        input: "${apply_effects.output}"
        params:
          include: ["title", "description", "hashtags"]
          style: "engaging"
          
      - name: "store_results"
        action: "database.store_clips"
        input: "${apply_effects.output}"
        params:
          with_metadata: "${generate_metadata.output}"

  # Publishing workflow
  auto_publishing:
    name: "Automated Publishing"
    trigger:
      type: "schedule"
      cron: "0 6,12,18 * * *"  # 6am, 12pm, 6pm
    
    steps:
      - name: "select_best_clips"
        action: "database.query"
        params:
          query: |
            SELECT * FROM clips 
            WHERE published = false 
            AND viral_potential_score > 0.8
            ORDER BY viral_potential_score DESC
            LIMIT 3
            
      - name: "predict_performance"
        action: "ai_agents.engagement_predictor.predict"
        input: "${select_best_clips.output}"
        params:
          timeframe: "7_days"
          
      - name: "optimize_timing"
        action: "publishing.optimize_schedule"
        input: "${predict_performance.output}"
        params:
          target_audience: "US"
          
      - name: "publish_content"
        action: "publishing.post"
        input: "${optimize_timing.output}"
        params:
          platforms: ["tiktok"]
          crosspost_delay: 30
        error_handling:
          tier: 3
          
      - name: "track_initial_metrics"
        action: "analytics.track"
        input: "${publish_content.output}"
        delay: "5m"

  # Pattern learning workflow
  pattern_learning:
    name: "Continuous Pattern Learning"
    trigger:
      type: "event"
      events: ["clip_published", "engagement_update", "viral_detected"]
    
    steps:
      - name: "collect_performance_data"
        action: "analytics.get_metrics"
        params:
          lookback: "24h"
          metrics: ["views", "likes", "shares", "retention"]
          
      - name: "identify_patterns"
        action: "ml.pattern_recognition"
        input: "${collect_performance_data.output}"
        params:
          min_confidence: 0.75
          
      - name: "validate_patterns"
        action: "ml.cross_validate"
        input: "${identify_patterns.output}"
        params:
          test_size: 0.2
          
      - name: "store_patterns"
        action: "pieces.store"
        input: "${validate_patterns.output}"
        condition: "${validate_patterns.output.accuracy > 0.8}"
        params:
          category: "viral_patterns"
          
      - name: "update_ai_models"
        action: "ai_agents.update_knowledge"
        input: "${store_patterns.output}"

  # Error recovery workflow
  error_recovery:
    name: "Automatic Error Recovery"
    trigger:
      type: "event"
      event: "error_detected"
    
    steps:
      - name: "classify_error"
        action: "error_handler.classify"
        params:
          include_context: true
          
      - name: "tier1_recovery"
        condition: "${classify_error.output.tier == 1}"
        action: "error_handler.retry"
        params:
          max_attempts: 3
          backoff: "exponential"
          
      - name: "tier2_recovery"
        condition: "${classify_error.output.tier == 2}"
        action: "error_handler.fallback"
        params:
          strategy: "alternative_path"
          
      - name: "tier3_recovery"
        condition: "${classify_error.output.tier == 3}"
        action: "error_handler.restart_service"
        params:
          graceful: true
          preserve_state: true
          
      - name: "tier4_alert"
        condition: "${classify_error.output.tier == 4}"
        action: "monitoring.alert"
        params:
          severity: "critical"
          auto_continue: true

  # Performance monitoring workflow
  performance_monitor:
    name: "Constitutional Performance Monitor"
    trigger:
      type: "schedule"
      interval: "*/1 * * * *"  # Every minute
    
    steps:
      - name: "collect_metrics"
        action: "monitoring.collect"
        params:
          services: ["all"]
          metrics: ["response_time", "throughput", "errors"]
          
      - name: "check_sla"
        action: "monitoring.validate_sla"
        input: "${collect_metrics.output}"
        params:
          api_threshold: 22ms
          db_threshold: 5ms
          
      - name: "auto_scale"
        condition: "${check_sla.output.violations > 0}"
        action: "infrastructure.scale"
        params:
          direction: "up"
          factor: 1.5
          
      - name: "optimize_queries"
        condition: "${check_sla.output.db_slow_queries > 0}"
        action: "database.optimize"
        params:
          auto_index: true
          vacuum: true

# Workflow orchestration rules
orchestration:
  max_concurrent_workflows: 10
  priority_order:
    - error_recovery
    - performance_monitor
    - auto_publishing
    - video_processing
    - content_discovery
    - pattern_learning
    
  resource_allocation:
    content_discovery:
      cpu: "10%"
      memory: "1GB"
    video_processing:
      cpu: "40%"
      memory: "4GB"
      gpu: "required"
    auto_publishing:
      cpu: "5%"
      memory: "512MB"
    pattern_learning:
      cpu: "20%"
      memory: "2GB"
    error_recovery:
      cpu: "5%"
      memory: "512MB"
    performance_monitor:
      cpu: "5%"
      memory: "256MB"
      
  failure_policy:
    max_retries: 3
    dead_letter_queue: true
    preserve_state: true
    continue_on_error: true